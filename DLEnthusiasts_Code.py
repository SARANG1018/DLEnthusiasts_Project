# -*- coding: utf-8 -*-
"""DLEnthusiasts.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MOwu1LYK5sXp_SIAJnW2Z5Go_5neahrl

# Team Name: DLEnthusiasts

# Team Members:
1. Sarang P. Kadakia
2. Vishwajeet Kulkarni

# About CIFAR-10 DATASET

The CIFAR-10 dataset is a widely used dataset for machine learning and computer vision tasks. It consists of 60,000 32x32 color images in 10 different classes, with 6,000 images per class. The dataset is divided into 50,000 training images and 10,000 test images
"""

!pip install torchviz

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torch.backends.cudnn as cudnn
import torchvision
import torchviz
import torchsummary
from torchvision.models import resnet18
import torchvision.transforms as transforms
from torchviz import make_dot
from torchvision.models.resnet import ResNet18_Weights

import matplotlib.pyplot as plt
import os
import argparse
import numpy as np
import pandas as pd

device = 'cuda' if torch.cuda.is_available() else 'cpu'
best_acc = 0
start_epoch = 0

"""# Data Preprocessing"""

# Computing the mean and standard deviation of the CIFAR-10 dataset across the three color channels (RGB)

transform = transforms.Compose([transforms.ToTensor()])

dataset = torchvision.datasets.CIFAR10(root = "./data", train = True, download = True, transform = transform)

loader = torch.utils.data.DataLoader(dataset, batch_size=50000, shuffle=False)

data = next(iter(loader))[0]

mean = data.mean(dim=(0,2,3))  # Compute mean over batch, height, and width
std = data.std(dim=(0,2,3))    # Compute std over batch, height, and width

cifar10_mean = mean.tolist()
cifar10_std = std.tolist()

print(cifar10_mean)
print(cifar10_std)

# Performing Normalization on train and test sets (Transforming the data)
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(cifar10_mean, cifar10_std),
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(cifar10_mean, cifar10_std),
])

# Dividing the data into train and test sets
trainset = torchvision.datasets.CIFAR10(root = './data', download = True, train = True, transform = transform_train)
# print(trainset[49999])

testset = torchvision.datasets.CIFAR10(root = './data', download = True, train = False, transform = transform_test)
# print(testset[0])

# Creating dataloaders for train and test sets
trainloader = torch.utils.data.DataLoader(trainset, batch_size = 16, shuffle = True, num_workers= 2)

testloader = torch.utils.data.DataLoader(testset, batch_size = 8, shuffle = False, num_workers= 2)

# Class & Base model
classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

base_model = resnet18(num_classes = 10)

x = iter(trainloader)
print(x)
images, label = x.__next__()
y = base_model(images)

print(torchsummary.summary(base_model, input_size =(3,32,32), device='cpu'))

"""# Model Definition

# Squeeze-and-Excitation (SE) block
This is being utilized for better feature weighting.
"""

class SEBlock(nn.Module):
    def __init__(self, channels, reduction=16):
        super(SEBlock, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),  # Ensuring valid FC size
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),  # bias = False: Uses bias for stability
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)   # Squeeze step
        y = self.fc(y).view(b, c, 1, 1)   # Excitation step
        return x * y.expand_as(x)

"""# Custom ResNet Block"""

# Input → Conv(3x3) → BN → ReLU → Conv(3x3) → BN → skip_connection → ReLU → Output
class BasicBlock(nn.Module):
    expansion = 1  # Expands channel dimensions

    def __init__(self, in_planes, planes, stride=1, use_se = True):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)

        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)

        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm2d(planes * self.expansion)

        self.se = SEBlock(planes* self.expansion) if use_se else None # adding SE block once enabled

        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != planes * self.expansion:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, planes * self.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * self.expansion)
            )

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = F.relu(self.bn2(self.conv2(out)))
        out = self.bn3(self.conv3(out))

        if self.se:
          out = self.se(out)

        out += self.shortcut(x)  # Skip connection
        out = F.relu(out)
        return out

"""# Custom Conv2D

CHARACTERISTICS:

1. Multiple feature maps from different layers are concatenated.
2. A 1×1 convolution refines the combined feature maps.
3. The refined feature maps are normalized and activated.
"""

class Root(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=1):
        super(Root, self).__init__()
        self.conv = nn.Conv2d(
            in_channels, out_channels, kernel_size,
            stride=1, padding = (kernel_size - 1) // 2, bias=False)
        self.bn = nn.BatchNorm2d(out_channels)

    def forward(self, xs):
      # x = sum(xs)
      x = torch.cat(xs, 1)  # opt 2: sum(xs)
      out = F.relu(self.bn(self.conv(x)))
      return out

"""# Tree
This will implement a hierarchical residual block that recursively stacks multiple residual blocks, allowing deep feature refinement with skip connections.
"""

class Tree(nn.Module):
    def __init__(self, block, in_channels, out_channels, level=3, stride=1, use_se = True):
        super(Tree, self).__init__()
        self.root = Root(2 * out_channels * block.expansion, out_channels)

        if level == 1:
            self.left_tree = block(in_channels, out_channels, stride=stride, use_se = use_se)
            # self.right_tree = block(out_channels, out_channels, stride=1, use_se = use_se)
            self.right_tree = block(out_channels*block.expansion, out_channels, stride=1, use_se = use_se)
        else:
            self.left_tree = Tree(block, in_channels, out_channels, level=level-1, stride=stride, use_se = use_se)
            self.right_tree = Tree(block, out_channels, out_channels, level=level-1, stride=1, use_se = use_se)

    def forward(self, x):
        out1 = self.left_tree(x)
        out2 = self.right_tree(out1)
        out = self.root([out1, out2])
        return out

"""# Our Model
This is team DLEnthusiasts ResNet Model architecture built from scratch.
"""

class DLEnthusiasts_ResNet(nn.Module):
    # def __init__(self, block=BasicBlock, num_classes=10, num_channels=None, filter_size=3, kernel_size=1, pool_size=4):
    def __init__(self, block=BasicBlock, num_classes=10, num_channels=[16, 32, 64, 128, 256], filter_size=3, kernel_size=1, pool_size=4, use_se = True):
        super(DLEnthusiasts_ResNet, self).__init__()

        # # best num_channels identified after hyperparameter fine-tuning
        # if num_channels is None:
        #   num_channels = [16, 32, 64, 128, 256, 256]

        self.base = nn.Sequential(
            nn.Conv2d(3, num_channels[0], kernel_size=filter_size, stride=1, padding=filter_size // 2, bias=False),
            nn.BatchNorm2d(num_channels[0]),
            nn.ReLU(True)
        )

        self.layer1 = nn.Sequential(
            nn.Conv2d(num_channels[0], num_channels[1], kernel_size=filter_size, stride=1, padding=filter_size // 2, bias=False),
            nn.BatchNorm2d(num_channels[1]),
            nn.ReLU(True)
        )

        self.layer2 = nn.Sequential(
            nn.Conv2d(num_channels[1], num_channels[2], kernel_size=filter_size, stride=1, padding=filter_size // 2, bias=False),
            nn.BatchNorm2d(num_channels[2]),
            nn.ReLU(True)
        )

        # Fixed Tree structure to maintain 2x channel consistency
        self.layer3 = Tree(block, num_channels[2], num_channels[3], level=1, stride=1)
        self.layer4 = Tree(block, num_channels[3], num_channels[4], level=2, stride=2)
        self.layer5 = Tree(block, num_channels[4], num_channels[4], level=2, stride=2)
        self.layer6 = Tree(block, num_channels[4], num_channels[4], level=1, stride=2)

        self.avgpool = nn.AdaptiveAvgPool2d((pool_size, pool_size))
        self.linear = nn.Linear(num_channels[-1] * (pool_size)**2, num_classes)

    def forward(self, x):
        out = self.base(x)
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = self.layer5(out)
        out = self.layer6(out)
        out = self.avgpool(out)

        out = torch.flatten(out, 1)

        # print("Shape after flattening", out.shape)

        out = self.linear(out)
        return out

dummy_input = torch.randn(16,3,32,32).to(device)
a = DLEnthusiasts_ResNet().to(device)(dummy_input)
print(a.shape)

"""# Training our Model

# HyperParamter Fine-Tuning with Bayesian Optimization
"""

!pip install optuna # Bayesian Optimization

import torch.optim as optim
import os
from tqdm import tqdm
import optuna

# Final Code for Hyperparameter Fine-tuning using Bayesian Optimization!

# def objective(trial):
#     torch.cuda.empty_cache()  # Clearing memory before starting new trial

#     # Sample hyperparameters from the search space
#     # Model architecture params
#     # ci : represents num_of_channels where Ci defines the number of channels (Ci) at different layers wher it allows to select best num_channels in each layer during training
#     Ci_opt = [trial.suggest_categorical("C1", [16, 32]),
#               trial.suggest_categorical("C2", [32, 64]),
#               trial.suggest_categorical("C3", [64, 128]),
#               trial.suggest_categorical("C4", [128, 256])]

#     C5_opt = C6_opt = Ci_opt[3]  # Ensuring consistency to avoid mismatches

#     Fi_opt = trial.suggest_categorical("Fi", [3, 5])  # Filter size
#     Ki_opt = trial.suggest_categorical("Ki", [1, 3])  # Kernel size in skip connections
#     P_opt = trial.suggest_categorical("P", [2, 4])    # Pooling size

#     lr = trial.suggest_float("lr", 1e-5, 1e-2, log=True)  # Learning rate
#     batch_size = trial.suggest_categorical("batch_size", [8, 16, 32])  # Reducing memory usage by selecting [8, 16, 32]
#     optimizer_choice = trial.suggest_categorical("optimizer", ["Adam", "SGD"])

#     # Defining model with optimized hyperparameters
#     model = DLEnthusiasts_ResNet(block=BasicBlock, num_classes=10,
#                                  num_channels=Ci_opt + [C5_opt, C6_opt],  # Ensuring proper matching
#                                  filter_size=Fi_opt,
#                                  kernel_size=Ki_opt, pool_size=P_opt).to(device)

#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay = 5e-4) if optimizer_choice == "Adam" else optim.SGD(model.parameters(), lr=lr, momentum=0.9)

#     # Using mixed precision training: It will store the model parameters in different datatype precision (FP16 vs FP32 vs FP64) to achieve significant performance and computational boost
#     scaler = torch.amp.GradScaler("cuda")

#     # Training to identify best set of hyperparameters
#     train_loss = 0.0
#     model.train()
#     subset_size = len(trainloader) // 4  # Using smaller dataset for faster tuning
#     accumulation_steps = 4  # Performing gradient accumulation (accumulating gradients over several batches and updating model parameters all at once)

#     for epoch in range(5):
#         running_loss = 0.0
#         optimizer.zero_grad()

#         for batch_idx, (inputs, targets) in enumerate(trainloader):
#             if batch_idx > subset_size:  # stopping early
#                 break

#             inputs, targets = inputs.to(device), targets.to(device)

#             with torch.amp.autocast("cuda"):
#                 outputs = model(inputs)
#                 loss = nn.CrossEntropyLoss()(outputs, targets) / accumulation_steps  # Normalizing the loss

#             # Backpropagation
#             scaler.scale(loss).backward()

#             if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(trainloader):
#                 scaler.step(optimizer)
#                 scaler.update()
#                 optimizer.zero_grad()

#             running_loss += loss.item() * accumulation_steps  # Rescaling loss

#         # Early stopping: We would stop if loss increases!
#         if epoch > 2 and running_loss > train_loss:
#             break
#         train_loss = running_loss

#     return train_loss  # Minimize loss

# # Running Bayesian Optimization
# study = optuna.create_study(direction="minimize") # minimizing loss occured during training (objective function)
# study.optimize(objective, n_trials=20)

# # Getting the best set of hyperparameters
# print("Best Hyperparameters:", study.best_params)

# we identified as best set of hyperparams: ['C1': 16, 'C2': 32, 'C3': 128, 'C4': 256, 'Fi': 3, 'Ki': 1, 'P': 4, 'lr': 0.00037167893563643987, 'batch_size': 16, 'optimizer': 'Adam']

optimized_num_channels = [16, 32, 128, 256, 256, 256]
my_model = DLEnthusiasts_ResNet(block = BasicBlock, num_classes = 10, num_channels = optimized_num_channels,kernel_size = 1, filter_size = 3, pool_size= 4, use_se = True).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(my_model.parameters(), lr = 0.00037167893563643987, weight_decay = 5e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 200)

train_losses = []
test_losses = []
train_accuracies = []
test_accuracies = []

# Training function:
def train(epoch):
    print(f'\nEpoch: {epoch}')
    my_model.train()
    train_loss = 0
    correct = 0
    total = 0

    trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)

    progress_bar = tqdm(enumerate(trainloader), total=len(trainloader), desc=f"Training Epoch {epoch}")

    for batch_idx, (inputs, targets) in progress_bar:
        inputs, targets = inputs.to(device), targets.to(device)

        optimizer.zero_grad()
        outputs = my_model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()

        progress_bar.set_postfix(loss=f"{train_loss/(batch_idx+1):.3f}", acc=f"{100.*correct/total:.2f}%")

    # Storing metrics for plotting
    train_losses.append(train_loss / len(trainloader))
    train_accuracies.append(100. * correct / total)

# Testing function
def test(epoch):
    global best_acc
    my_model.eval()
    test_loss = 0
    correct = 0
    total = 0

    predictions = []   # my list to store the ID and its corresponding labels(classes)

    with torch.no_grad():
        progress_bar = tqdm(enumerate(testloader), total=len(testloader), desc=f"Testing Epoch {epoch}")

        for batch_idx, (inputs, targets) in progress_bar:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = my_model(inputs)
            loss = criterion(outputs, targets)

            test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

            # Storing Image ID and corresponding label
            for j in range(len(predicted)):
                image_id = batch_idx * testloader.batch_size + j
                predictions.append([image_id, predicted[j].item()])

            progress_bar.set_postfix(loss=f"{test_loss/(batch_idx+1):.3f}", acc=f"{100.*correct/total:.2f}%")

    # Storing metrics for plotting
    test_losses.append(test_loss / len(testloader))
    test_accuracies.append(100. * correct / total)

    # Saving the best model's checkpoint and CSV
    acc = 100. * correct / total
    if acc > best_acc:
        print('Saving best model...')
        state = {
            'net': my_model.state_dict(),
            'acc': acc,
            'epoch': epoch,
        }
        if not os.path.isdir('checkpoint'):
            os.makedirs('checkpoint')
        torch.save(state, './checkpoint/ckpt.pth')
        best_acc = acc

        # Saving predictions to CSV File
        df = pd.DataFrame(predictions, columns=['ID', 'Label'])
        df.to_csv("submission.csv", index=False)
        print("Predictions saved to submission.csv")

for epoch in range(start_epoch, start_epoch + 19):
# for epoch in range(0, 30):
    train(epoch)
    test(epoch)
    scheduler.step()

"""# Plotting Graphs"""

import matplotlib.pyplot as plt



def plot_metrics():
    epochs = range(1, len(train_losses) + 1)

    # Plotting Loss
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, 'b-', label='Training Loss')
    plt.plot(epochs, test_losses, 'r-', label='Testing Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training & Testing Loss')
    plt.legend()

    # Plotting Accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, train_accuracies, 'b-', label='Training Accuracy')
    plt.plot(epochs, test_accuracies, 'r-', label='Testing Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy (%)')
    plt.title('Training & Testing Accuracy')
    plt.legend()

    plt.show()

plot_metrics()

